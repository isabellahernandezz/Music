README.md
# ðŸŽ¶ Proyecto ETL en PySpark con SQLite

Este proyecto implementa un **pipeline ETL (Extract â†’ Transform â†’ Load)** para procesar datasets musicales de Spotify usando **PySpark**.  
Los datos se limpian, transforman y se almacenan en mÃºltiples formatos: **Parquet, CSV y SQLite**.

---

## ðŸ“‚ Estructura del Proyecto



Music/
â”œâ”€â”€ Config/
â”‚ â””â”€â”€ config.py # ConfiguraciÃ³n de rutas y parÃ¡metros
â”œâ”€â”€ Extract/
â”‚ â””â”€â”€ extractor.py # LÃ³gica de extracciÃ³n de datos (CSV â†’ Spark DataFrame)
â”œâ”€â”€ Transform/
â”‚ â””â”€â”€ transformer.py # Transformaciones y limpieza de datos
â”œâ”€â”€ Load/
â”‚ â””â”€â”€ loader.py # Carga en Parquet, CSV y SQLite
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ input/ # Archivos de entrada (CSV originales)
â”‚ â”‚ â”œâ”€â”€ sample_music.csv
â”‚ â”‚ â”œâ”€â”€ high_popularity_spotify_data_limpio.csv
â”‚ â””â”€â”€ output/ # Resultados del ETL (Parquet, CSV, SQLite)
â”‚ â”œâ”€â”€ music_clean_final.parquet
â”‚ â”œâ”€â”€ music_clean_csv/
â”‚ â””â”€â”€ etl_data.db
â”œâ”€â”€ main.py # OrquestaciÃ³n del pipeline ETL
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ verificar_salida.py # Script auxiliar para validar outputs
â””â”€â”€ README.md # DocumentaciÃ³n


---

## âš™ï¸ Requisitos

- Python 3.10+
- PySpark
- Pandas
- SQLite (viene incluido con Python)

Instala dependencias:
```bash
pip install pyspark pandas
ðŸš€ EjecuciÃ³n del ETL
1. Ejemplo con dataset de prueba
python main.py --master local[*] \
  --input data/input/sample_music.csv \
  --output data/output/music_clean.parquet \
  --format parquet

2. Ejemplo con dataset real
python main.py --master local[*] \
  --input data/input/high_popularity_spotify_data_limpio.csv \
  --output data/output/music_clean.parquet \
  --format parquet



ðŸ› ï¸ Transformaciones aplicadas

NormalizaciÃ³n de columnas (artist, duration_ms, popularity).

CÃ¡lculo de duration_min y duration_sec.

ClasificaciÃ³n de popularidad en categorÃ­as:

high (>= 80)

medium (50â€“79)

low (< 50)





ðŸ”„ Flujo de Trabajo con GitFlow

El repositorio sigue la metodologÃ­a GitFlow:

main â†’ rama estable con versiones de producciÃ³n.

develop â†’ rama de desarrollo activo.

feature/* â†’ ramas para nuevas funcionalidades.

release/* â†’ ramas de preparaciÃ³n para despliegue.

Ejemplo:

git checkout develop
git checkout -b feature/nueva-transformacion
# ... desarrollar ...
git commit -am "Agrego nueva transformaciÃ³n en Transformer"
git push origin feature/nueva-transformacion


Cuando estÃ© listo:

git checkout develop
git merge feature/nueva-transformacion

ðŸ“š Frameworks recomendados (para versiones futuras)

Airflow â†’ OrquestaciÃ³n y programaciÃ³n de ETLs.

Luigi â†’ Pipelines acadÃ©micos y de investigaciÃ³n.

Spark MLlib â†’ AnÃ¡lisis predictivo sobre datos transformados.

Delta Lake â†’ Control de versiones en datos (Parquet avanzado)